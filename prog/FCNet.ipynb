{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux pleinement connectés \n",
    "\n",
    "Cet exercice fait suite au devoir 1.  L'objectif ici est d'implanter un réseau pleinement connecté avec une approche plus modulaire. Pour chaque couche, vous serez appelé à implanter une fonction `forward` et une fonction `backward`. La fonction `forward` reçoit en entrée un tenseur `x`, des poids `w` et possiblement d'autres parameters, et retourne le tenseur de sortie de la couche `out`.  La fonction retourne aussi une variable `cache`  contenant des données utilisés pour la rétropropagation (fonction `backward`).  La structure de la fonction `forward` est la suivante : \n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "N'oubliez pas que `x` est une `batch` et donc conbient plus d'un élément.\n",
    "\n",
    "En rétropropagation, la fonction `backward` de la couche reçoit en entrée un tenseur de dérivées `dout` ainsi que la liste `cache` calculée lors de la propagation avant (fonction `forward`).  Elle retourne deux tenseurs de gradients: un par rapport à ses entrée (`dx`) et un par rapport à ses poids (`dw`) (et parfois un par rapport aux bias `db`).  La structure de la fonction `backward` est la suivante : \n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "Une fois ce type de couches implanté, il sera possible de les combiner ensemble et ainsi construire des réseaux de neurones de différentes architectures.\n",
    "\n",
    "En plus des réseaux pleinement connectés, nous explorerons différents algorithme de descente de gradient et  introduirons *Dropout* et *Batch Norm*.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the ift725 directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n",
      "setup done!\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "#import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ift725.layers import *\n",
    "from ift725.classifiers.fc_net import *\n",
    "from ift725.data_utils import get_CIFAR10_data\n",
    "from ift725.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from ift725.solver import Solver\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "print('setup done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couche pleinement connectée : propagation avant\n",
    "Dans le fichier `ift725/layers.py`, vous devez coder la fonction `forward_fully_connected` et la tester avec le code de la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape  =  (1, 2, 2, 3)\n",
      "w-shape  =  (12, 1)\n",
      "b-shape  =  (1,)\n",
      "out =  [[36.7]]\n",
      "correct_out =  36.7\n",
      "Testing forward_fully_connected function:\n",
      "difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Test the forward_fully_connected function : batch 1 and 1 output neuron\n",
    "\n",
    "input_shape = (2, 2, 3) # an 2x2x3 input variable (a CIFAR10 image would have a 32x32x3 shape)\n",
    "\n",
    "input_size = np.prod(input_shape) # here 12\n",
    "weight_size = np.prod(input_shape) # here 12\n",
    "\n",
    "x = np.floor(np.linspace(-0.1, 0.5, num=input_size).reshape(1, *input_shape)*10)\n",
    "w = np.floor(np.linspace(-0.2, 0.3, num=weight_size).reshape(weight_size, 1)*10)\n",
    "b = np.linspace(-0.3, 0.1, num=1)\n",
    "\n",
    "print('x-shape  = ', x.shape)\n",
    "print('w-shape  = ', w.shape)\n",
    "print('b-shape  = ', b.shape)\n",
    "\n",
    "out, _ = forward_fully_connected(x, w, b)\n",
    "correct_out = 36.7\n",
    "\n",
    "print('out = ', out)\n",
    "print('correct_out = ', correct_out)\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing forward_fully_connected function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape  =  (2, 2, 2, 3)\n",
      "w-shape  =  (12, 1)\n",
      "b-shape  =  (1,)\n",
      "out =  [[14.7]\n",
      " [20.7]]\n",
      "correct_out =  [14.7 20.7]\n",
      "Testing forward_fully_connected function:\n",
      "difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Test the forward_fully_connected function : batch 2 and 1 output neuron\n",
    "\n",
    "num_inputs = 2          # batch of 2 input variables\n",
    "input_shape = (2, 2, 3) # an 2x2x3 input variable (a CIFAR10 image would have a 32x32x3 shape)\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape) # here 2x12 = 24\n",
    "weight_size = np.prod(input_shape) # here 12\n",
    "\n",
    "x = np.floor(np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)*10)\n",
    "w = np.floor(np.linspace(-0.2, 0.3, num=weight_size).reshape(weight_size, 1)*10)\n",
    "b = np.linspace(-0.3, 0.1, num=1)\n",
    "\n",
    "print('x-shape  = ', x.shape)\n",
    "print('w-shape  = ', w.shape)\n",
    "print('b-shape  = ', b.shape)\n",
    "\n",
    "out, _ = forward_fully_connected(x, w, b)\n",
    "correct_out = np.array([14.7, 20.7])\n",
    "\n",
    "print('out = ', out)\n",
    "print('correct_out = ', correct_out)\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing forward_fully_connected function:')\n",
    "print('difference: ', rel_error(out.T, correct_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape  =  (2, 2, 2, 3)\n",
      "w-shape  =  (12, 2)\n",
      "b-shape  =  (2,)\n",
      "out =  [[12.7 14.1]\n",
      " [11.7 23.1]]\n",
      "correct_out =  [[12.7 14.1]\n",
      " [11.7 23.1]]\n",
      "Testing forward_fully_connected function:\n",
      "difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Test the forward_fully_connected function : batch 2 and 2 output neurons\n",
    "num_inputs = 2          # batch of 2 input variables\n",
    "input_shape = (2, 2, 3) # each variable as a 2x2x3 shape (a CIFAR10 RBG image would have a 32x32x3 shape)\n",
    "output_dim = 2          # the output has 2 neurons\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)  #here 2x2x2x3 = 24\n",
    "weight_size = output_dim * np.prod(input_shape) #here 2x12 = 24\n",
    "\n",
    "x = np.floor(np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)*10)\n",
    "w = np.floor(np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)*10)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "print('x-shape  = ', x.shape)\n",
    "print('w-shape  = ', w.shape)\n",
    "print('b-shape  = ', b.shape)\n",
    "\n",
    "out, _ = forward_fully_connected(x, w, b)\n",
    "correct_out = np.array([[ 12.7,  14.1],\n",
    "                        [ 11.7,  23.1]])\n",
    "\n",
    "print('out = ', out)\n",
    "print('correct_out = ', correct_out)\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing forward_fully_connected function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couche pleinement connectée : rétro-propagation\n",
    "If faut maintenant implanter la fonction `backward_fully_connected` et tester votre code avec un gradient numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing backward_fully_connected function:\n",
      "dx error:  1.907101144973397e-10\n",
      "dw error:  3.452467280877471e-09\n",
      "db error:  3.251321937683576e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the backward_fully_connected function\n",
    "# Here a case for a batch of 10 elements\n",
    "# Each elements has a 2x3 size\n",
    "# The layer has 5 output neurons\n",
    "\n",
    "x = np.random.randn(10, 2, 3)  # batch of 10 elements, each of size 2x3\n",
    "w = np.random.randn(6, 5)      # 2x3=6 weigts times 5 output neurones\n",
    "b = np.random.randn(5)         # one bias for each output neurone\n",
    "dout = np.random.randn(10, 5)  # the upcoming gradient at each output neuron and for each element of the batch\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_fully_connected(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: forward_fully_connected(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: forward_fully_connected(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = forward_fully_connected(x, w, b)\n",
    "dx, dw, db = backward_fully_connected(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print('Testing backward_fully_connected function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))  #Gradient with respect to the input x : size 10x2x3\n",
    "print('dw error: ', rel_error(dw_num, dw))  #Gradient with respect to the weights w : size 5x6\n",
    "print('db error: ', rel_error(db_num, db))  #Gradient with respect to the bias : size 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couche ReLU : propagation avant\n",
    "Il faut implanter la fonction d'activation ReLU avec la fonction `relu_forward`.  Testez votre implantation avec la cellule que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing forward_relu function:\n",
      "difference:  4.999999798022158e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = forward_relu(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-8\n",
    "print('Testing forward_relu function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couche ReLU : rétropropagation\n",
    "Maintenant il faut implanter la rétro-propagation pour une fonction d'activation ReLU via la fonction `relu_backward`.  Testez votre implantation avec le gradient numérique que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 0.80444143 -1.74761101]\n",
      " [-1.04087367 -0.79312995]]\n",
      "dout  =  [[-1.43840491 -0.4807464 ]\n",
      " [ 0.0468146   0.19085212]]\n",
      "Testing backward_relu function:\n",
      "dx error:  2.2755480682055385e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(2, 2)\n",
    "dout = np.random.randn(*x.shape) # Upstream gradient that retropropagates at that layer\n",
    "print(\"x = \", x)\n",
    "print(\"dout  = \", dout)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: forward_relu(xx)[0], x, dout)\n",
    "\n",
    "_, cache = forward_relu(x)\n",
    "dx = backward_relu(dout, cache)\n",
    "# The error should be around 1e-12\n",
    "print('Testing backward_relu function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couches \"Combo\"\n",
    "Souvent, on combine une couche pleinement connectée avec une fonction d'activation comme ReLU. Afin de simplifier ces situations, nous avons différentes fonctions à cet effet dans `ift725/layer_combo.py`.\n",
    "\n",
    "Pour l'instant, nous porterons notre attention sur les fonctions `forward_fully_connected_transform_relu` et `backward_fully_connected_transform_relu`.  Vous pouvez vérifier le code à l'aide de la vérification numérique que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing forward_fully_connected_transform_relu:\n",
      "dx error:  1.2666194306352793e-10\n",
      "dw error:  5.266711944521852e-10\n",
      "db error:  7.82663844611185e-12\n"
     ]
    }
   ],
   "source": [
    "from ift725.layer_combo import forward_fully_connected_transform_relu, backward_fully_connected_transform_relu\n",
    "\n",
    "x = np.random.randn(2, 3, 4)  # Batch of 2 elements of size 3x4\n",
    "w = np.random.randn(12, 10)   # 10 output neurons, each associated with 12=3x4 weights\n",
    "b = np.random.randn(10)       # 10 biases\n",
    "dout = np.random.randn(2, 10) # up stream gradient for each neuron (10) and each batch element (2)\n",
    "\n",
    "out, cache = forward_fully_connected_transform_relu(x, w, b)\n",
    "dx, dw, db = backward_fully_connected_transform_relu(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: forward_fully_connected_transform_relu(xx, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda ww: forward_fully_connected_transform_relu(x, ww, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda bb: forward_fully_connected_transform_relu(x, w, bb)[0], b, dout)\n",
    "\n",
    "# Error should be around 1e-10\n",
    "print('Testing forward_fully_connected_transform_relu:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de perte : Softmax et SVM\n",
    "Au devoir 1, vous avez implanter ces deux fonctions de perte.  Vous devez donc récupérer votre code et l'adapter aux fonctions `softmax_loss` et `svm_loss` du fichier `ift725/layers.py`.\n",
    "\n",
    "Afin de vous assurer que tout fonctionne pour le mieux, exécutez le code que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.99854044000682\n",
      "dx error:  3.038735505103329e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.3024396017532247\n",
      "dx error:  8.815774102561171e-09\n"
     ]
    }
   ],
   "source": [
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau à deux couches\n",
    "Au tp1, vous avez implanté un réseau à deux couches à l'intérieur d'une seule classe monolitique. Maintenant que les couches ont un design plus modulaire, vous devez implanter un réseau à deux couches de façon modulaire.\n",
    "\n",
    "Avec le fichier `ift725/classifiers/fc_net.py`, vous devez compléter l'implantation de la classe `TwoLayerNeuralNet`. Le design de cette classe est le prototype pour les autres réseaux utilisés dans ce devoir.  Par conséquent, soyez attentifs et assurez-vous de bien comprendre cet API. Vous pouvez exécuter la cellule que voici pour tester votre code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "score difference =  5.115852452775016e-08\n"
     ]
    }
   ],
   "source": [
    "# First, lets try a forward pass for a minibatch of 3 elements of size 5, with an hidden layer of size 50 and 7 classes\n",
    "\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-2\n",
    "model = TwoLayerNeuralNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "print('score difference = ', scores_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss difference =  4.61053417666335e-12\n",
      "loss =  63.9539735065371   correct_loss =  63.9539735065\n",
      "loss difference =  3.710454166139243e-11\n"
     ]
    }
   ],
   "source": [
    "# Now lets compute the loss with and without regularization\n",
    "y = np.asarray([0, 5, 1])\n",
    "\n",
    "model.reg = 0.0  # NO REG\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "print('loss difference = ', abs(loss - correct_loss))\n",
    "\n",
    "model.reg = 1.0  # WITH REG\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 63.9539735065\n",
    "print('loss = ', loss, '  correct_loss = ', correct_loss)\n",
    "print('loss difference = ', abs(loss - correct_loss))\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.83e-08\n",
      "W2 relative error: 3.31e-10\n",
      "b1 relative error: 9.83e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.3\n",
      "W1 relative error: 1.01e-07\n",
      "W2 relative error: 1.71e-08\n",
      "b1 relative error: 9.88e-09\n",
      "b2 relative error: 2.24e-09\n",
      "Running numeric gradient check with reg =  0.6\n",
      "W1 relative error: 1.25e-07\n",
      "W2 relative error: 5.21e-08\n",
      "b1 relative error: 5.68e-09\n",
      "b2 relative error: 8.97e-10\n",
      "Running numeric gradient check with reg =  0.9\n",
      "W1 relative error: 1.35e-05\n",
      "W2 relative error: 4.03e-06\n",
      "b1 relative error: 1.17e-08\n",
      "b2 relative error: 8.35e-10\n"
     ]
    }
   ],
   "source": [
    "# Now lets compute the loss with different regularization terms\n",
    "\n",
    "for reg in [0.0, 0.3, 0.6, 0.9]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "Au tp1, l'entraînement des modèles était couplé aux modèles. Suivant un design plus modulaire, dans ce tp nous avons séparé le code d'entraînement et le code des modèles dans différentes classes.\n",
    "\n",
    "Familiarisez-vous avec le code `ift725/solver.py` et assurez-vous de bien en comprendre le fonctionnement. Après, utilisez un `Solver` pour entraîner le `TwoLayerNeuralNet` et atteindre environ `50%` de justesse en validation sur le base de donnée CIFAR10 stockée dans la variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 2450) loss: 2.303535\n",
      "(Epoch 0 / 5) train acc: 0.116000; val_acc: 0.115000\n",
      "(Iteration 11 / 2450) loss: 2.282300\n",
      "(Iteration 21 / 2450) loss: 2.214957\n",
      "(Iteration 31 / 2450) loss: 2.195921\n",
      "(Iteration 41 / 2450) loss: 2.113078\n",
      "(Iteration 51 / 2450) loss: 2.113386\n",
      "(Iteration 61 / 2450) loss: 1.972412\n",
      "(Iteration 71 / 2450) loss: 2.056607\n",
      "(Iteration 81 / 2450) loss: 1.845315\n",
      "(Iteration 91 / 2450) loss: 1.815968\n",
      "(Iteration 101 / 2450) loss: 1.759933\n",
      "(Iteration 111 / 2450) loss: 2.017639\n",
      "(Iteration 121 / 2450) loss: 1.749796\n",
      "(Iteration 131 / 2450) loss: 1.868561\n",
      "(Iteration 141 / 2450) loss: 1.691495\n",
      "(Iteration 151 / 2450) loss: 1.692814\n",
      "(Iteration 161 / 2450) loss: 1.724999\n",
      "(Iteration 171 / 2450) loss: 1.878205\n",
      "(Iteration 181 / 2450) loss: 1.719491\n",
      "(Iteration 191 / 2450) loss: 1.710375\n",
      "(Iteration 201 / 2450) loss: 1.796105\n",
      "(Iteration 211 / 2450) loss: 1.694531\n",
      "(Iteration 221 / 2450) loss: 1.706442\n",
      "(Iteration 231 / 2450) loss: 1.758228\n",
      "(Iteration 241 / 2450) loss: 1.667829\n",
      "(Iteration 251 / 2450) loss: 1.923597\n",
      "(Iteration 261 / 2450) loss: 1.693553\n",
      "(Iteration 271 / 2450) loss: 1.636463\n",
      "(Iteration 281 / 2450) loss: 1.610994\n",
      "(Iteration 291 / 2450) loss: 1.502764\n",
      "(Iteration 301 / 2450) loss: 1.610472\n",
      "(Iteration 311 / 2450) loss: 1.667118\n",
      "(Iteration 321 / 2450) loss: 1.516095\n",
      "(Iteration 331 / 2450) loss: 1.748834\n",
      "(Iteration 341 / 2450) loss: 1.752229\n",
      "(Iteration 351 / 2450) loss: 1.482294\n",
      "(Iteration 361 / 2450) loss: 1.584045\n",
      "(Iteration 371 / 2450) loss: 1.472861\n",
      "(Iteration 381 / 2450) loss: 1.701756\n",
      "(Iteration 391 / 2450) loss: 1.573179\n",
      "(Iteration 401 / 2450) loss: 1.599290\n",
      "(Iteration 411 / 2450) loss: 1.536521\n",
      "(Iteration 421 / 2450) loss: 1.484873\n",
      "(Iteration 431 / 2450) loss: 1.403238\n",
      "(Iteration 441 / 2450) loss: 1.508837\n",
      "(Iteration 451 / 2450) loss: 1.591139\n",
      "(Iteration 461 / 2450) loss: 1.614871\n",
      "(Iteration 471 / 2450) loss: 1.468457\n",
      "(Iteration 481 / 2450) loss: 1.599250\n",
      "(Epoch 1 / 5) train acc: 0.426000; val_acc: 0.430000\n",
      "(Iteration 491 / 2450) loss: 1.745305\n",
      "(Iteration 501 / 2450) loss: 1.761079\n",
      "(Iteration 511 / 2450) loss: 1.565610\n",
      "(Iteration 521 / 2450) loss: 1.414932\n",
      "(Iteration 531 / 2450) loss: 1.526624\n",
      "(Iteration 541 / 2450) loss: 1.601769\n",
      "(Iteration 551 / 2450) loss: 1.422583\n",
      "(Iteration 561 / 2450) loss: 1.607579\n",
      "(Iteration 571 / 2450) loss: 1.399186\n",
      "(Iteration 581 / 2450) loss: 1.600327\n",
      "(Iteration 591 / 2450) loss: 1.579627\n",
      "(Iteration 601 / 2450) loss: 1.825921\n",
      "(Iteration 611 / 2450) loss: 1.457687\n",
      "(Iteration 621 / 2450) loss: 1.514257\n",
      "(Iteration 631 / 2450) loss: 1.644427\n",
      "(Iteration 641 / 2450) loss: 1.512721\n",
      "(Iteration 651 / 2450) loss: 1.425493\n",
      "(Iteration 661 / 2450) loss: 1.735466\n",
      "(Iteration 671 / 2450) loss: 1.730757\n",
      "(Iteration 681 / 2450) loss: 1.533031\n",
      "(Iteration 691 / 2450) loss: 1.464170\n",
      "(Iteration 701 / 2450) loss: 1.501536\n",
      "(Iteration 711 / 2450) loss: 1.337275\n",
      "(Iteration 721 / 2450) loss: 1.823631\n",
      "(Iteration 731 / 2450) loss: 1.478490\n",
      "(Iteration 741 / 2450) loss: 1.588606\n",
      "(Iteration 751 / 2450) loss: 1.700460\n",
      "(Iteration 761 / 2450) loss: 1.581849\n",
      "(Iteration 771 / 2450) loss: 1.408363\n",
      "(Iteration 781 / 2450) loss: 1.575607\n",
      "(Iteration 791 / 2450) loss: 1.404176\n",
      "(Iteration 801 / 2450) loss: 1.464954\n",
      "(Iteration 811 / 2450) loss: 1.541137\n",
      "(Iteration 821 / 2450) loss: 1.632590\n",
      "(Iteration 831 / 2450) loss: 1.383815\n",
      "(Iteration 841 / 2450) loss: 1.374353\n",
      "(Iteration 851 / 2450) loss: 1.432181\n",
      "(Iteration 861 / 2450) loss: 1.512991\n",
      "(Iteration 871 / 2450) loss: 1.268867\n",
      "(Iteration 881 / 2450) loss: 1.488461\n",
      "(Iteration 891 / 2450) loss: 1.439914\n",
      "(Iteration 901 / 2450) loss: 1.255889\n",
      "(Iteration 911 / 2450) loss: 1.545546\n",
      "(Iteration 921 / 2450) loss: 1.533609\n",
      "(Iteration 931 / 2450) loss: 1.444309\n",
      "(Iteration 941 / 2450) loss: 1.351319\n",
      "(Iteration 951 / 2450) loss: 1.522268\n",
      "(Iteration 961 / 2450) loss: 1.261957\n",
      "(Iteration 971 / 2450) loss: 1.447744\n",
      "(Epoch 2 / 5) train acc: 0.491000; val_acc: 0.452000\n",
      "(Iteration 981 / 2450) loss: 1.478105\n",
      "(Iteration 991 / 2450) loss: 1.619253\n",
      "(Iteration 1001 / 2450) loss: 1.300520\n",
      "(Iteration 1011 / 2450) loss: 1.614089\n",
      "(Iteration 1021 / 2450) loss: 1.305074\n",
      "(Iteration 1031 / 2450) loss: 1.575923\n",
      "(Iteration 1041 / 2450) loss: 1.194980\n",
      "(Iteration 1051 / 2450) loss: 1.341222\n",
      "(Iteration 1061 / 2450) loss: 1.266848\n",
      "(Iteration 1071 / 2450) loss: 1.485277\n",
      "(Iteration 1081 / 2450) loss: 1.464011\n",
      "(Iteration 1091 / 2450) loss: 1.460570\n",
      "(Iteration 1101 / 2450) loss: 1.337106\n",
      "(Iteration 1111 / 2450) loss: 1.513214\n",
      "(Iteration 1121 / 2450) loss: 1.177786\n",
      "(Iteration 1131 / 2450) loss: 1.341191\n",
      "(Iteration 1141 / 2450) loss: 1.436209\n",
      "(Iteration 1151 / 2450) loss: 1.261385\n",
      "(Iteration 1161 / 2450) loss: 1.591529\n",
      "(Iteration 1171 / 2450) loss: 1.293626\n",
      "(Iteration 1181 / 2450) loss: 1.614515\n",
      "(Iteration 1191 / 2450) loss: 1.511947\n",
      "(Iteration 1201 / 2450) loss: 1.316069\n",
      "(Iteration 1211 / 2450) loss: 1.253695\n",
      "(Iteration 1221 / 2450) loss: 1.624546\n",
      "(Iteration 1231 / 2450) loss: 1.263711\n",
      "(Iteration 1241 / 2450) loss: 1.422234\n",
      "(Iteration 1251 / 2450) loss: 1.827479\n",
      "(Iteration 1261 / 2450) loss: 1.366865\n",
      "(Iteration 1271 / 2450) loss: 1.381302\n",
      "(Iteration 1281 / 2450) loss: 1.361223\n",
      "(Iteration 1291 / 2450) loss: 1.472507\n",
      "(Iteration 1301 / 2450) loss: 1.332878\n",
      "(Iteration 1311 / 2450) loss: 1.359364\n",
      "(Iteration 1321 / 2450) loss: 1.234193\n",
      "(Iteration 1331 / 2450) loss: 1.619981\n",
      "(Iteration 1341 / 2450) loss: 1.461913\n",
      "(Iteration 1351 / 2450) loss: 1.338450\n",
      "(Iteration 1361 / 2450) loss: 1.295873\n",
      "(Iteration 1371 / 2450) loss: 1.322747\n",
      "(Iteration 1381 / 2450) loss: 1.402641\n",
      "(Iteration 1391 / 2450) loss: 1.243925\n",
      "(Iteration 1401 / 2450) loss: 1.402855\n",
      "(Iteration 1411 / 2450) loss: 1.409624\n",
      "(Iteration 1421 / 2450) loss: 1.491225\n",
      "(Iteration 1431 / 2450) loss: 1.552654\n",
      "(Iteration 1441 / 2450) loss: 1.327151\n",
      "(Iteration 1451 / 2450) loss: 1.393524\n",
      "(Iteration 1461 / 2450) loss: 1.457602\n",
      "(Epoch 3 / 5) train acc: 0.522000; val_acc: 0.478000\n",
      "(Iteration 1471 / 2450) loss: 1.481395\n",
      "(Iteration 1481 / 2450) loss: 1.169535\n",
      "(Iteration 1491 / 2450) loss: 1.392490\n",
      "(Iteration 1501 / 2450) loss: 1.285268\n",
      "(Iteration 1511 / 2450) loss: 1.530092\n",
      "(Iteration 1521 / 2450) loss: 1.306908\n",
      "(Iteration 1531 / 2450) loss: 1.494687\n",
      "(Iteration 1541 / 2450) loss: 1.337921\n",
      "(Iteration 1551 / 2450) loss: 1.259643\n",
      "(Iteration 1561 / 2450) loss: 1.579021\n",
      "(Iteration 1571 / 2450) loss: 1.350694\n",
      "(Iteration 1581 / 2450) loss: 1.165727\n",
      "(Iteration 1591 / 2450) loss: 1.373049\n",
      "(Iteration 1601 / 2450) loss: 1.353888\n",
      "(Iteration 1611 / 2450) loss: 1.451668\n",
      "(Iteration 1621 / 2450) loss: 1.484328\n",
      "(Iteration 1631 / 2450) loss: 1.403988\n",
      "(Iteration 1641 / 2450) loss: 1.309245\n",
      "(Iteration 1651 / 2450) loss: 1.490646\n",
      "(Iteration 1661 / 2450) loss: 1.248709\n",
      "(Iteration 1671 / 2450) loss: 1.178490\n",
      "(Iteration 1681 / 2450) loss: 1.186601\n",
      "(Iteration 1691 / 2450) loss: 1.333016\n",
      "(Iteration 1701 / 2450) loss: 1.302150\n",
      "(Iteration 1711 / 2450) loss: 1.383279\n",
      "(Iteration 1721 / 2450) loss: 1.426012\n",
      "(Iteration 1731 / 2450) loss: 1.262010\n",
      "(Iteration 1741 / 2450) loss: 1.563022\n",
      "(Iteration 1751 / 2450) loss: 1.254441\n",
      "(Iteration 1761 / 2450) loss: 1.280752\n",
      "(Iteration 1771 / 2450) loss: 1.359141\n",
      "(Iteration 1781 / 2450) loss: 1.408059\n",
      "(Iteration 1791 / 2450) loss: 1.304092\n",
      "(Iteration 1801 / 2450) loss: 1.359293\n",
      "(Iteration 1811 / 2450) loss: 1.256001\n",
      "(Iteration 1821 / 2450) loss: 1.378133\n",
      "(Iteration 1831 / 2450) loss: 1.637964\n",
      "(Iteration 1841 / 2450) loss: 1.461869\n",
      "(Iteration 1851 / 2450) loss: 1.490148\n",
      "(Iteration 1861 / 2450) loss: 1.430041\n",
      "(Iteration 1871 / 2450) loss: 1.448678\n",
      "(Iteration 1881 / 2450) loss: 1.382707\n",
      "(Iteration 1891 / 2450) loss: 1.403277\n",
      "(Iteration 1901 / 2450) loss: 1.364161\n",
      "(Iteration 1911 / 2450) loss: 1.483448\n",
      "(Iteration 1921 / 2450) loss: 1.257337\n",
      "(Iteration 1931 / 2450) loss: 1.529799\n",
      "(Iteration 1941 / 2450) loss: 1.237976\n",
      "(Iteration 1951 / 2450) loss: 1.292226\n",
      "(Epoch 4 / 5) train acc: 0.532000; val_acc: 0.477000\n",
      "(Iteration 1961 / 2450) loss: 1.513663\n",
      "(Iteration 1971 / 2450) loss: 1.135713\n",
      "(Iteration 1981 / 2450) loss: 1.282526\n",
      "(Iteration 1991 / 2450) loss: 1.357687\n",
      "(Iteration 2001 / 2450) loss: 1.460403\n",
      "(Iteration 2011 / 2450) loss: 1.271652\n",
      "(Iteration 2021 / 2450) loss: 1.427092\n",
      "(Iteration 2031 / 2450) loss: 1.272325\n",
      "(Iteration 2041 / 2450) loss: 1.295464\n",
      "(Iteration 2051 / 2450) loss: 1.455604\n",
      "(Iteration 2061 / 2450) loss: 1.333362\n",
      "(Iteration 2071 / 2450) loss: 1.434720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 2081 / 2450) loss: 1.315578\n",
      "(Iteration 2091 / 2450) loss: 1.313752\n",
      "(Iteration 2101 / 2450) loss: 1.273543\n",
      "(Iteration 2111 / 2450) loss: 1.474424\n",
      "(Iteration 2121 / 2450) loss: 1.323992\n",
      "(Iteration 2131 / 2450) loss: 1.391699\n",
      "(Iteration 2141 / 2450) loss: 1.379722\n",
      "(Iteration 2151 / 2450) loss: 1.390538\n",
      "(Iteration 2161 / 2450) loss: 1.306621\n",
      "(Iteration 2171 / 2450) loss: 1.132056\n",
      "(Iteration 2181 / 2450) loss: 1.338303\n",
      "(Iteration 2191 / 2450) loss: 1.422441\n",
      "(Iteration 2201 / 2450) loss: 1.410332\n",
      "(Iteration 2211 / 2450) loss: 1.271643\n",
      "(Iteration 2221 / 2450) loss: 1.243855\n",
      "(Iteration 2231 / 2450) loss: 1.303394\n",
      "(Iteration 2241 / 2450) loss: 1.100207\n",
      "(Iteration 2251 / 2450) loss: 1.143815\n",
      "(Iteration 2261 / 2450) loss: 1.299980\n",
      "(Iteration 2271 / 2450) loss: 1.151021\n",
      "(Iteration 2281 / 2450) loss: 1.221167\n",
      "(Iteration 2291 / 2450) loss: 1.458149\n",
      "(Iteration 2301 / 2450) loss: 1.278875\n",
      "(Iteration 2311 / 2450) loss: 1.353394\n",
      "(Iteration 2321 / 2450) loss: 1.315474\n",
      "(Iteration 2331 / 2450) loss: 1.250753\n",
      "(Iteration 2341 / 2450) loss: 1.339331\n",
      "(Iteration 2351 / 2450) loss: 1.259925\n",
      "(Iteration 2361 / 2450) loss: 1.287161\n",
      "(Iteration 2371 / 2450) loss: 1.445195\n",
      "(Iteration 2381 / 2450) loss: 1.275276\n",
      "(Iteration 2391 / 2450) loss: 1.271943\n",
      "(Iteration 2401 / 2450) loss: 1.200223\n",
      "(Iteration 2411 / 2450) loss: 1.121996\n",
      "(Iteration 2421 / 2450) loss: 1.108478\n",
      "(Iteration 2431 / 2450) loss: 1.374953\n",
      "(Iteration 2441 / 2450) loss: 1.282424\n",
      "(Epoch 5 / 5) train acc: 0.557000; val_acc: 0.490000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "model = TwoLayerNeuralNet()\n",
    "solver = None\n",
    "solver = Solver(model, data,\n",
    "                  update_rule='sgd',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  lr_decay=0.95,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  verbose = True)\n",
    "solver.train()\n",
    "solver.best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones multi-couches\n",
    "Maintenant vous devez implanter un réseau ayant un nombre arbitraire de couches.\n",
    "\n",
    "Pour ce faire, prenez connaissance de la classe `FullyConnectedNeuralNet` du fichier `ift725/classifiers/fc_net.py`.\n",
    "\n",
    "Vous devez implanter **l'initialization, la propagation avant et la rétro-propagation**. Pour le moment, ne vous souciez pas de dropout ni de batch norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fonction de perte et vérification du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine cellule effectue une vérification dilligente.  Exécutez la cellule afin de vous assurez que la loss avec et sans régularisation fonctionne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  3.3976428676905224\n",
      "W1 relative error: 5.53e-08\n",
      "W2 relative error: 3.71e-08\n",
      "b1 relative error: 1.55e-09\n",
      "b2 relative error: 7.62e-10\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  10.413045230363586\n",
      "W1 relative error: 9.43e-09\n",
      "W2 relative error: 1.97e-07\n",
      "b1 relative error: 5.21e-08\n",
      "b2 relative error: 2.81e-09\n"
     ]
    }
   ],
   "source": [
    "from ift725.classifiers.fc_net import *\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,)) \n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNeuralNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "    \n",
    "  # Relative error should be below 1e-5\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "Pourquoi croyez-vous que les résultats de la cellule précédentes font foi d'une bonne fonction de perte?\n",
    "     \n",
    "**Votre réponse:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autre vérification diligente, assurez-vous que votre code peut \"overfitter\" sur un petit ensemble de 50 images. Pour ce faire, essayons un réseau à 3 couches cachées ayant chacune 100 neurones. Une recherche d'hyper-paramètres sera effectué pour trouver le bon taux d'apprentissage (learning rate) ainsi que le `weight_scale`.  Vous devriez être capable d'atteindre une justesse en entraînement de 100% avec 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-97-ea3f9dbde741>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-97-ea3f9dbde741>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    model = FullyConnectedNeuralNet(hidden_dims = ,weight_scale=1e-2)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "best_weight_scale = 0.\n",
    "best_learning_rate = 0.\n",
    "best_training_acc = 0.\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Utilisez une instance de Solver pour entrainer un réseau à 3 couches #\n",
    "#  et 100 neurones par couche à overfitter 50 images de CIFAR10.  Il est     #\n",
    "#  suggéré d'effectuer une recherche d'hyperparamètres pour trouver le bon   #\n",
    "#  `learning_rate` et le bon `weight_scale`.                                 #\n",
    "##############################################################################\n",
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "model = FullyConnectedNeuralNet(hidden_dims = ,weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()\n",
    "\n",
    "##############################################################################\n",
    "#                             FIN DE VOTRE CODE                              #\n",
    "##############################################################################\n",
    "\n",
    "print('The best learning_rate, weight_scale and training accuracy are',best_weight_scale, best_learning_rate, best_training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "# import math\n",
    "marker_size = 100\n",
    "x_scatter, x_label = [np.log10(x[0]) for x in results], 'log weight scale'\n",
    "y_scatter, y_label = [np.log10(x[1]) for x in results], 'log learning rate'\n",
    "\n",
    "# plot validation accuracy\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Train accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, faites la même chose pour un réseau à 5 couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Utilisez une instance de Solver pour entrainer un réseau à 5 couches #\n",
    "#  à 100 neurones à overfitter 50 images de CIFAR10.  Il est suggérer de     #\n",
    "#  d'effectuer une recherche d'hyperparamètres pour trouver le bon           #\n",
    "#  `learning_rate` et le bon `weight_scale`.                                 #\n",
    "##############################################################################\n",
    "\n",
    "def uniform(minv, maxv):\n",
    "    return np.random.rand() * (maxv - minv) + minv\n",
    "\n",
    "results = {}\n",
    "for _ in range(40):\n",
    "    weight_scale = 10 ** uniform(-2, -1)\n",
    "    learning_rate = 10 ** uniform(-4, -2)\n",
    "    print(weight_scale, learning_rate, '\\n')\n",
    "    \n",
    "    model = FullyConnectedNeuralNet([100, 100, 100, 100],\n",
    "                  weight_scale=weight_scale, dtype=np.float64)\n",
    "    solver = Solver(model, small_data,\n",
    "                    print_every=10, num_epochs=20, batch_size=25,\n",
    "                    update_rule='sgd',\n",
    "                    optim_config={\n",
    "                      'learning_rate': learning_rate,\n",
    "                    }, verbose=False)\n",
    "    solver.train()\n",
    "    train_acc = solver.train_acc_history[-1]\n",
    "    print('final loss:', solver.loss_history[-1], ' train_acc:', train_acc)\n",
    "    print('\\n')\n",
    "    plt.plot(solver.loss_history)\n",
    "    results[(weight_scale, learning_rate)] = train_acc\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             FIN DE VOTRE CODE                              #\n",
    "##############################################################################\n",
    "best_weight_scale = 0.\n",
    "best_learning_rate = 0.\n",
    "best_training_acc = 0.\n",
    "print('The best learning_rate, weight_scale and training accuracy are',best_weight_scale, best_learning_rate, best_training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "# import math\n",
    "marker_size = 100\n",
    "x_scatter, x_label = [np.log10(x[0]) for x in results], 'log weight scale'\n",
    "y_scatter, y_label = [np.log10(x[1]) for x in results], 'log learning rate'\n",
    "\n",
    "# plot validation accuracy\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Train accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descente de gradient ++\n",
    "Jusqu'à présent nous avons utilisé l'algorithmes de base de la descente de gradient (SGD-stochastic gradient descent). Ici nous testerons d'autres algorithmes plus sophistiqués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "SGD+momentum est très largement utilisé.  Ouvrez  `ift725/optim.py` et prenez connaissance du code et implémentez la fonction `sgd_momentum` et exécutez la cellule que voici. Votre erreur devrait être inféreieure à 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "    [-0.39994,    -0.34737526, -0.29481053, -0.24224579, -0.18968105],\n",
    "    [-0.13711632, -0.08455158, -0.03198684,  0.02057789,  0.07314263],\n",
    "    [ 0.12570737,  0.17827211,  0.23083684,  0.28340158,  0.33596632],\n",
    "    [ 0.38853105,  0.44109579,  0.49366053,  0.54622526,  0.59879   ]])\n",
    "expected_velocity = np.asarray([\n",
    "    [-0.06 ,       0.00684211,  0.07368421,  0.14052632,  0.20736842],\n",
    "    [ 0.27421053,  0.34105263,  0.40789474,  0.47473684,  0.54157895],\n",
    "    [ 0.60842105,  0.67526316,  0.74210526,  0.80894737,  0.87578947],\n",
    "    [ 0.94263158,  1.00947368,  1.07631579,  1.14315789,  1.21      ]])\n",
    "\n",
    "# Error should be below 1e-06\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, excécutez cette cellule.  Normalement, le réseau à 6 couches devrait s'entraîner plus rapidement avec SGD+momentum qu'avec SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNeuralNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=10, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, '-o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp et Adam\n",
    "RMSProp [1] et Adam [2] sont d'autres algorithmes de descente de gradient dont le code est dans le fichier `ift725/optim.py`.   Alors que le code de Adam vous est fournit, vous devez rédigé celui de RMSProp.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "import numpy as np\n",
    "from ift725.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "    [-0.39,       -0.33846964, -0.2868865,  -0.23525427, -0.18357633],\n",
    "    [-0.13185574, -0.0800953,  -0.02829757,  0.02353511,  0.07540058],\n",
    "    [ 0.12729687,  0.17922215,  0.23117507,  0.28315533,  0.33516143],\n",
    "    [ 0.38719188,  0.43924528,  0.49132033,  0.54341585,  0.59553073]])\n",
    "expected_cache = np.asarray([\n",
    "    [0.6,        0.61510526, 0.63021053, 0.64531579, 0.66042105],\n",
    " [0.67552632, 0.69063158, 0.70573684, 0.72084211, 0.73594737],\n",
    " [0.75105263, 0.76615789, 0.78189474, 0.79805263, 0.81421053],\n",
    " [0.83036842, 0.84652632, 0.86268421, 0.87884211, 0.895     ]])  \n",
    "\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from ift725.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, config = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter le code que voici afin de comparer ces différent algorithmes.  En pricipe Adam devrait être le meilleur algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNeuralNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=10, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînez un bon model!\n",
    "Entraînez le meilleur réseau de neurones possible sur CIFAR-10 et mettez le meilleur modèle dans la variable `best_model`. Vous devriez avoir au moins une justesse 50% (voire même 55%) en validation et en test.\n",
    "\n",
    "Plus tard dans le devoir, on vous demandera d'entrainer et de tester une réseau convolutionnel sur CIFAR-10.  Vous verrez alors que cette architecture est supérieure aux réseaus de neurones pleinement connectés.\n",
    "\n",
    "NOTE: il serait judicieux de compléter le notebook `BatchNormalization.ipynb` et `Dropout.ipynb` avant de compléter cette dernière partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_delete = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_delete:\n",
    "    trys = []\n",
    "    best_try = -1\n",
    "    best_val_acc = 0\n",
    "    print('Deleted trys')\n",
    "else:\n",
    "    print('Did not delete trys')\n",
    "do_delete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Entrainez le meilleur FullyConnectedNeuralNet que vous pouvez sur les  #\n",
    "#  données CIFAR-10. Vous pourriez trouver la normalization par lots et le     #\n",
    "#  dropout utile. Stockez votre meilleur modèle dans la variable best_model.   #\n",
    "################################################################################\n",
    "\n",
    "def uniform(minv, maxv):\n",
    "    return np.random.rand() * (maxv - minv) + minv\n",
    "\n",
    "if 'trys' not in locals():\n",
    "    trys = []\n",
    "    best_try = -1\n",
    "    best_val_acc = 0\n",
    "for i in range(1):\n",
    "    # reg 0.00779190546432  lr 0.000423844376859\n",
    "    # reg 0.000204588367827 lr 0.000529341067109\n",
    "    weight_scale = 3e-2  # 10 ** uniform(-3, -1)\n",
    "    lr = 10 ** -2.5  # 10 ** uniform(-4, -2)\n",
    "    reg = 1e-10  # 10 ** uniform(-6, -3)\n",
    "    \n",
    "    model = FullyConnectedNeuralNet([100] * 5, weight_scale=weight_scale, reg=reg, use_batchnorm=True)\n",
    "\n",
    "    solver = Solver(model, data,\n",
    "                  num_epochs=30, batch_size=100,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': lr\n",
    "                  },\n",
    "                  print_every=200,\n",
    "                  verbose=True)\n",
    "    solver.train()\n",
    "    \n",
    "    max_val_acc = np.max(solver.val_acc_history)\n",
    "    cur_index = len(trys)\n",
    "    print('Try', cur_index, 'Max accu. val.', max_val_acc, 'p:', weight_scale, reg, lr, ('Record!' if max_val_acc > best_val_acc else ''))\n",
    "    trys.append({\n",
    "            'ws': weight_scale, 'reg': reg, 'lr': lr,\n",
    "            'maxvacc': max_val_acc,\n",
    "            'lossh': solver.loss_history,\n",
    "            'tacch': solver.train_acc_history,\n",
    "            'vacch': solver.val_acc_history,\n",
    "            'model': model\n",
    "        })\n",
    "    \n",
    "    if max_val_acc > best_val_acc:\n",
    "        best_val_acc = max_val_acc\n",
    "        best_try = cur_index\n",
    "        \n",
    "print('Best try:', best_try)\n",
    "print('Total tries', len(trys))\n",
    "################################################################################\n",
    "#                              FIN DE VOTRE CODE                               #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "forget = 0\n",
    "new_tries = trys[forget:]\n",
    "marker_size = 100\n",
    "#x_scatter, x_label = [np.log10(x['ws']) for x in new_tries], 'log weight scale'\n",
    "x_scatter, x_label = [np.log10(x['lr']) for x in new_tries], 'log lr'\n",
    "y_scatter, y_label = [np.log10(x['reg']) for x in new_tries], 'log reg'\n",
    "\n",
    "# plot validation accuracy\n",
    "colors = [x['maxvacc'] for x in new_tries] # default size of markers is 20\n",
    "isorted = np.argsort(colors)\n",
    "x_scatter = np.asarray(x_scatter)[isorted]\n",
    "y_scatter = np.asarray(y_scatter)[isorted]\n",
    "colors = np.asarray(colors)[isorted]\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = trys[best_try]\n",
    "best_try = -1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(trys[best_try]['lossh'], '-')\n",
    "plt.plot(ref['lossh'], '-')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(trys[best_try]['tacch'], '-', label='Train')\n",
    "plt.plot(trys[best_try]['vacch'], '-', label='Valid')\n",
    "plt.plot(ref['tacch'], '-', label='Train ref')\n",
    "plt.plot(ref['vacch'], '-', label='Valid ref')\n",
    "plt.legend(loc='lower center')\n",
    "\n",
    "plt.tight_layout(pad=0, w_pad=0, h_pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your model\n",
    "Run your best model on the validation and test sets. You should achieve above 53% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trys[best_try]['model']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "X_val  = data['X_val']\n",
    "y_val  = data['y_val']\n",
    "y_test_pred = np.argmax(best_model.loss(X_test), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(X_val), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == y_val).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
