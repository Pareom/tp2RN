{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau à convolution\n",
    "Jusqu'à présent, nous avons utilisé des réseaus multi-couches pleinement connectées.  Dans ce notebook, nous explorerons les réseaux à convolution, une architecture beaucoup plus adaptée à l'analyse d'images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ift725.classifiers.cnn import *\n",
    "from ift725.data_utils import get_CIFAR10_data\n",
    "from ift725.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from ift725.layers import *\n",
    "from ift725.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution: propagation avant naïve\n",
    "Au coeur d'une CNN est l'opération de convolution. Dans le fichier `ift725/layers.py`, vous devez implanter une couche de convolution dans la function `forward_convolutional_naive`. \n",
    "\n",
    "Pas besoin que le code soit efficace; vous pouvez l'implanter de la façon qui vous semble la plus facile à comprendre.\n",
    "\n",
    "Les cellules que voici vous permettront de tester votre code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_shape = (1, 1, 4, 4)  # (N=1 batch, C=1 channels, H=4 largeur du feature map, W=4 Hauteur du feature map)\n",
    "w_shape = (1, 1, 2, 2)  # (F=1 Nb feature maps en sortie, C=1 channels, HH=2 hauteur du filtre, WW=2 largeur du filtre)\n",
    "x = np.floor(10*np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape))\n",
    "w = np.floor(10*np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape))\n",
    "b = np.floor(10*np.linspace(-0.1, 0.2, num=w.shape[0]))\n",
    "\n",
    "correct_out = np.array([[[[5, 6, 5],\n",
    "                            [6, 7, 8],\n",
    "                            [8, 8, 9]]]])\n",
    "\n",
    "print('Input = \\n', x)\n",
    "print('Filter = \\n', w)\n",
    "print('Bias = ', b)\n",
    "conv_param = {'stride': 1, 'pad': 0}\n",
    "out, _ = forward_convolutional_naive(x, w, b, conv_param, True)\n",
    "print(out)\n",
    "\n",
    "# Compare your output to ours; difference should be around 1e-8\n",
    "print('Testing forward_convolutional_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.quick_layers import conv_forward_fast, conv_backward_fast\n",
    "\n",
    "x_shape = (1, 2, 4, 4)  # (N=1 batch, C=2 channels, H=4 largeur du feature map, W=4 Hauteur du feature map)\n",
    "w_shape = (1, 2, 2, 2)  # (F=1 Nb feature maps en sortie, C=2 channels, HH=2 hauteur du filtre, WW=2 largeur du filtre)\n",
    "x = np.floor(10*np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape))\n",
    "w = np.floor(10*np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape))\n",
    "b = np.floor(10*np.linspace(-0.1, 0.2, num=w.shape[0]))\n",
    "\n",
    "correct_out = np.array([[[[19, 21, 20],\n",
    "                            [21, 22, 22],\n",
    "                            [21, 22, 23]]]])\n",
    "\n",
    "print('Input = \\n', x)\n",
    "print('Filter = \\n', w)\n",
    "print('Bias = ', b)\n",
    "conv_param = {'stride': 1, 'pad': 0}\n",
    "out, _ = forward_convolutional_naive(x, w, b, conv_param, True)\n",
    "print(out)\n",
    "\n",
    "# Compare your output to ours; difference should be around 1e-8\n",
    "print('Testing forward_convolutional_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.quick_layers import conv_forward_fast, conv_backward_fast\n",
    "\n",
    "x_shape = (1, 2, 4, 4)  # (N=1 batch, C=2 channels, H=4 largeur du feature map, W=4 Hauteur du feature map)\n",
    "w_shape = (1, 2, 4, 4)  # (F=1 Nb feature maps en sortie, C=2 channels, HH=4 hauteur du filtre, WW=4 largeur du filtre)\n",
    "x = np.floor(10*np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape))\n",
    "w = np.floor(10*np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape))\n",
    "b = np.floor(10*np.linspace(-0.1, 0.2, num=w.shape[0]))\n",
    "\n",
    "correct_out = np.array([[[[52, 49],\n",
    "                            [37, 29]]]])\n",
    "\n",
    "print('Input = \\n', x)\n",
    "print('Filter = \\n', w)\n",
    "print('Bias = ', b)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = forward_convolutional_naive(x, w, b, conv_param, True)\n",
    "print(out)\n",
    "\n",
    "# Compare your output to ours; difference should be around 1e-8\n",
    "print('Testing forward_convolutional_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)  # (N=2 batch, C=3 channels, H=4 largeur du feature map, W=4 Hauteur du feature map)\n",
    "w_shape = (3, 3, 4, 4)  # (F=3 nb feature maps en sortie, C=3 channels, HH=4 hauteur du filtre, WW=4 largeur du filtre)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = forward_convolutional_naive(x, w, b, conv_param, True)\n",
    "correct_out = np.array([[[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]]])\n",
    "\n",
    "\n",
    "# Compare your output to ours; difference should be around 1e-8\n",
    "print('Testing forward_convolutional_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traiter une image pour valider une convolution\n",
    "\n",
    "On peut également valider son code en convoluant une image couleur.  Pour ce faire, la cellule que voici charge en mémoire deux images couleurs et définit deux filtres : une filtre de détection de contours et un filtre de conversion RGB->niveaux de gris. La convolution est par la suite appliquée à chaque image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "kitten, puppy = imread('kitten.jpg'), imread('puppy.jpg')\n",
    "# kitten is wide, and puppy is already square\n",
    "d = kitten.shape[1] - kitten.shape[0]\n",
    "kitten_cropped = kitten[:, int(d/2):int(-d/2), :]\n",
    "\n",
    "img_size = 200   # Make this smaller if it runs too slow\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = resize(puppy, (img_size, img_size)).transpose((2, 0, 1))\n",
    "x[1, :, :, :] = resize(kitten_cropped, (img_size, img_size)).transpose((2, 0, 1))\n",
    "\n",
    "# Set up a convolutional weights holding 2 filters, each 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "# The first filter converts the image to grayscale.\n",
    "# Set up the red, green, and blue channels of the filter.\n",
    "w[0, 0, :, :] = [[0, 0, 0], [0, 0.333, 0], [0, 0, 0]]\n",
    "w[0, 1, :, :] = [[0, 0, 0], [0, 0.334, 0], [0, 0, 0]]\n",
    "w[0, 2, :, :] = [[0, 0, 0], [0, 0.333, 0], [0, 0, 0]]\n",
    "\n",
    "# Second filter detects horizontal edges in the blue channel.\n",
    "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "\n",
    "# Vector of biases. We don't need any bias for the grayscale\n",
    "# filter, but for the edge detection filter we want to add 128\n",
    "# to each output so that nothing is negative.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Compute the result of convolving each input in x with each filter in w,\n",
    "# offsetting by b, and storing the results in out.\n",
    "out, _ = forward_convolutional_naive(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Show the original images and the results of the conv operation\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_noax(puppy, normalize=False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_noax(out[0, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_noax(out[0, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_noax(kitten_cropped, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_noax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_noax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution: rétropropagation naïve\n",
    "Implémentez une rétropropagation convolutive naïve dans la fonction `backward_convolutional_naive` du fichier `ift725/layers.py`. Ici aussi, vous pouvez implémentez une solution simple non vectorisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question :\n",
    "\n",
    "Avant de commencer à coder, expliquez mathématiquement en quoi consiste le gradient d'une convolution par rapport aux variables x, w et b, à savoir les variables dx, dw et db dans le code.  Pour vous aider, vous pouvez vous référez au document que voici:\n",
    "\n",
    "https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199\n",
    "\n",
    "## Votre réponse : ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_convolutional_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: forward_convolutional_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: forward_convolutional_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = forward_convolutional_naive(x, w, b, conv_param)\n",
    "dx, dw, db = backward_convolutional_naive(dout, cache)\n",
    "\n",
    "# Your errors should be around 1e-9'\n",
    "print('Testing backward_convolutional_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max pooling: propagation avant naïve.\n",
    "Codez une propagation avant naïve pour l'opération de max-pooling avec la fonction `forward_max_pooling_naive` dans le fichier `ift725/layers.py`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = forward_max_pooling_naive(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be around 1e-8.\n",
    "print('Testing forward_max_pooling_naive function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max pooling: rétropropagation naïve\n",
    "Codez la rétro-propagation de l'opération de max-pooling via la fonction `backward_max_pooling_naive` dans le fichier `ift725/layers.py`.\n",
    "\n",
    "Vous pouvez tester votre code avec la cellule que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(1, 1, 4, 4)  # (N=1 batch, C=1 channels, H=4 largeur du feature map, W=4 Hauteur du feature map)\n",
    "dout = np.random.randn(1, 1, 2, 2)  # (N=1 batch, C=1 channels, H=2 largeur du feature map, W=2 Hauteur du feature map)\n",
    "\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_max_pooling_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = forward_max_pooling_naive(x, pool_param)\n",
    "dx = backward_max_pooling_naive(dout, cache)\n",
    "\n",
    "print('intput x = \\n', x)\n",
    "print('max_pool(x) = \\n', out)\n",
    "print('upcoming gradient = \\n', dout)\n",
    "print('gradient num = \\n', dx_num)\n",
    "print('gradient naive = \\n', dx)\n",
    "\n",
    "# Your error should be around 1e-12\n",
    "print('Testing backward_max_pooling_naive function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3, 2, 8, 8) # (N=3 batch, C=2 channels, H=8 largeur du feature map, W=8 Hauteur du feature map)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_max_pooling_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = forward_max_pooling_naive(x, pool_param)\n",
    "dx = backward_max_pooling_naive(dout, cache)\n",
    "\n",
    "# Your error should be around 1e-12\n",
    "print('Testing backward_max_pooling_naive function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution : version rapide\n",
    "Afin de vous simplifier la vie (car nous sommes gentils après tout!) nous vous fournissons le code pour effectuer une convolution et des opération de pooling rapidement via le fichier `ift725/quick_layers.py`.\n",
    "\n",
    "Cette version de la convolution provient d'un code Cython que vous pouvez compiler comme suit:\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```\n",
    "\n",
    "L'API des fonctions rapide est la même que celle des fonctions que vous avez implémenté au paravant: la propagation avant reçoit en entrée une mini-batch de données `x`, des poids `w`, `b`  et des paramètres et produit une sortie `out` ainsi qu'une `cache` pour la rétropropagation.  La rétropropagation quant à elle reçoit en entrée un gradient provenant de la fin de réseau `dout` ainsi que l'objet `cache` et retourne les gradients par rapport aux données (`dx`), aux poids (`dw`) et au biais (`bd`).\n",
    "\n",
    "Vous pouvez comparer la différence en temps de calcul entre la version naïve et optimisée de ces fonction avec la cellule que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.quick_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "\n",
    "x = np.random.randn(100, 3, 31, 31)\n",
    "w = np.random.randn(25, 3, 3, 3)\n",
    "b = np.random.randn(25,)\n",
    "dout = np.random.randn(100, 25, 16, 16)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = forward_convolutional_naive(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing conv_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Difference: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive, dw_naive, db_naive = backward_convolutional_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting conv_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))\n",
    "print('dw difference: ', rel_error(dw_naive, dw_fast))\n",
    "print('db difference: ', rel_error(db_naive, db_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.quick_layers import max_pool_forward_fast, max_pool_backward_fast\n",
    "\n",
    "x = np.random.randn(100, 3, 32, 32)\n",
    "dout = np.random.randn(100, 3, 16, 16)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = forward_max_pooling_naive(x, pool_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing pool_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('difference: ', rel_error(out_naive, out_fast))\n",
    "naive = t1 - t0\n",
    "fast = t2 - t1\n",
    "t0 = time()\n",
    "dx_naive = backward_max_pooling_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting pool_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))\n",
    "naive += t1 - t0\n",
    "fast += t2 - t1\n",
    "\n",
    "print('\\nnaive', naive)\n",
    "print('fast', fast)\n",
    "print('naive/fast', naive/fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couches convolutives \"combo\"\n",
    "Nous avons utilisé des couches \"combo\" en combinant plusieurs opérations en une. Dans le fichier `ift725/layer_combo.py` le code de quelques opérations \"combo\" vous est fourni alors que d'autres ne l'est pas; à vous de le rédiger.  Vous pouvez tester votre code à l'aide des cellules que voici:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.layer_combo import forward_convolutional_relu, backward_convolutional_relu\n",
    "\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = forward_convolutional_relu(x, w, b, conv_param)\n",
    "dx, dw, db = backward_convolutional_relu(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_convolutional_relu(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: forward_convolutional_relu(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: forward_convolutional_relu(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "print('Testing convolutional_relu:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.layer_combo import forward_convolutional_relu_pool, backward_convolutional_relu_pool\n",
    "\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = forward_convolutional_relu_pool(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = backward_convolutional_relu_pool(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: forward_convolutional_relu_pool(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: forward_convolutional_relu_pool(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: forward_convolutional_relu_pool(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "print('Testing convolutional_relu_pool')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet à trois couches\n",
    "Maintenant que toutes les couches ont été codées, vous pouvez les combiner et créer un réseau à convolution à trois couches.\n",
    "\n",
    "Dans le fichier `ift725/cnn.py`, complétez le code de la classe `ThreeLayerConvolutionalNet`. Utilisez les cellules que voici pour débugger votre code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification dilligente de la fonction de perte\n",
    "Après avoir compléter le code de votre réseau, une des premières chose à faire est de valider la fonction de perte. Comme d'habitude, lorsqu'on initialise un réseau avec des poids aléatoire, on s'attends à ce que la perte d'une entropie croisée (sans régularisation) soit d'environ `-log(1/nb_classes)`. Avec la régularisation, la perte devrait être un peu plus élevée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerConvolutionalNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (no regularization): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification du gradient\n",
    "Une fois que la perte fonctionne, comme d'habitude on vérifier les fonctions de rétro-propagation à l'aide d'un gradient numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)  # this is like a batch of 2 RGB images of size 16x16 \n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "X = np.random.randn(num_inputs, *input_dim)*10\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ThreeLayerConvolutionalNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7, reg=reg,\n",
    "                          dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "\n",
    "#Should be lower than 1e-03\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-7)    \n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sur-apprendre un petit ensemble de données\n",
    "Une façon simple que votre réseau fonctionne bien, il est d'usage de s'assurer que le réseau est capable de sur-apprendre un petit ensemble de donnnées.  Après 10 epochs, votre réseau devrait avoir une justesse d'entraînement de plus de 85% mais une justesse de validation de moins de 25%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 40\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvolutionalNet(weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=10,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un réseau à convolution\n",
    "Entraîner un CNN à trois couches. Après 1 epoch, vous devriez atteindre une justesse d'au moins 40% en validation.  La justesse devrait atteindre 60% après 10 epochs.  Mais attention, l'entraînement peut prendre plusieurs minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ThreeLayerConvolutionalNet(weight_scale=0.001, hidden_dim=500, reg=0.001)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=200)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des filtres\n",
    "Vous pouvez visualiser les filtres de la première couche du réseau entraîné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ift725.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Batch Normalization\n",
    "Nous avons vu que batch normalization est une technique fort untile pour entraîner un réseau pleinement connecté. La même technique peut être utilisée pour entrainée un CNN, mais avec quelques ajustements; c'est ce que nous appelons \"spatial batch normalization.\"\n",
    "\n",
    "De base, batch-norm prend en entrée un tenseur de taille `(N, D)` et produit en sortie un autre tenseur de taille `(N, D)` dont la normalisation est effectuée à travers le mini-batch de taill `N`.  Par contre, pour une couche convolutive, batch norma prend en entrée un tenseur de taille `(N, C, H, W)` et produit en sortie un autre tenseur de taille `(N, C, H, W)` où `N` est la taille du minibatch, `(H, W)` est la hauteur et la largeur du tenseur et `C` est le nombre de `feature maps`.\n",
    "\n",
    "Le spatial batch norm calcule une moyenne et une variance pour chaque feature map `C` à travers la dimension du mini-batch `N`, et les dimensions spatiales `H` et `W`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial batch normalization: propagation avant\n",
    "\n",
    "Dans le fichier `ift725/layers.py`, la fonction `forward_spatial_batch_normalization` calcule la propagation avant du spatial batch norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after spatial batch normalization\n",
    "\n",
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "\n",
    "print('Before spatial batch normalization:')\n",
    "print('  Shape: ', x.shape)\n",
    "print('  Means: ', x.mean(axis=(0, 2, 3)))\n",
    "print('  Stds: ', x.std(axis=(0, 2, 3)))\n",
    "\n",
    "# Means should be close to zero and stds close to one\n",
    "gamma, beta = np.ones(C), np.zeros(C)\n",
    "bn_param = {'mode': 'train'}\n",
    "out, _ = forward_spatial_batch_normalization(x, gamma, beta, bn_param)\n",
    "print('After spatial batch normalization:')\n",
    "print('  Shape: ', out.shape)\n",
    "print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
    "print('  Stds: ', out.std(axis=(0, 2, 3)))\n",
    "\n",
    "# Means should be close to beta and stds close to gamma\n",
    "gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n",
    "out, _ = forward_spatial_batch_normalization(x, gamma, beta, bn_param)\n",
    "print('After spatial batch normalization (nontrivial gamma, beta):')\n",
    "print('  Shape: ', out.shape)\n",
    "print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
    "print('  Stds: ', out.std(axis=(0, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the test-time forward pass by running the training-time\n",
    "# forward pass many times to warm up the running averages, and then\n",
    "# checking the means and variances of activations after a test-time\n",
    "# forward pass.\n",
    "\n",
    "N, C, H, W = 10, 4, 11, 12\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(C)\n",
    "beta = np.zeros(C)\n",
    "for t in range(50):\n",
    "  x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "  forward_spatial_batch_normalization(x, gamma, beta, bn_param)\n",
    "bn_param['mode'] = 'test'\n",
    "x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "a_norm, _ = forward_spatial_batch_normalization(x, gamma, beta, bn_param)\n",
    "\n",
    "# Means should be close to zero and stds close to one, but will be\n",
    "# noisier than training-time forward passes.\n",
    "print('After spatial batch normalization (test-time):')\n",
    "print('  means: ', a_norm.mean(axis=(0, 2, 3))) \n",
    "print('  stds: ', a_norm.std(axis=(0, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial batch normalization: rétro-propagation\n",
    "Dans le fichier `ift725/layers.py`, la fonction `backward_spatial_batch_normalization` implémente la rétro-propagation de cette couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "gamma = np.random.randn(C)\n",
    "beta = np.random.randn(C)\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: forward_spatial_batch_normalization(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: forward_spatial_batch_normalization(x, gamma, beta, bn_param)[0]\n",
    "fb = lambda b: forward_spatial_batch_normalization(x, gamma, beta, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "_, cache = forward_spatial_batch_normalization(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = backward_spatial_batch_normalization(dout, cache)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "print('dbeta error: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points bonus\n",
    "**10% de bonus** si vous proposez une nouvelle classe permettant d'entraîner un réseau comme celui-ci\n",
    "\n",
    "**([conv-relu-bn]xN1-[pool])xN2 - [FC-relu]xM - [softmax]**\n",
    "\n",
    "où *N1>=2, N2>=3* et *M>=2* et avec du *dropout*.  Le réseau doit être constitué de couches *combo*.  Votre code doit être dans les fichiers `ift725/classifiers/mycnn.py` (qu'il vous faudra créer) et `ift725/layer_combo.py`.\n",
    "\n",
    "### Autre bonus:\n",
    "**10% de bonus** si votre architecture est modulaire, c'est-à-dire que les valeurs *N1*, *N2* et *M* ne sont pas *hardcodées* mais peuvent être spécifiées dans le constructeur de la classe.\n",
    "\n",
    "Amusez-vous bien!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a really good model on CIFAR-10"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
